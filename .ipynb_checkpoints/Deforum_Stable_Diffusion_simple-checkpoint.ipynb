{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/markusstrasser/deforum/blob/main/Deforum_Stable_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c442uQJ_gUgy"
   },
   "source": [
    "# **Deforum Stable Diffusion v0.5**\n",
    "[Stable Diffusion](https://github.com/CompVis/stable-diffusion) by Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer and the [Stability.ai](https://stability.ai/) Team. [K Diffusion](https://github.com/crowsonkb/k-diffusion) by [Katherine Crowson](https://twitter.com/RiversHaveWings). You need to get the ckpt file and put it on your Google Drive first to use this. It can be downloaded from [HuggingFace](https://huggingface.co/CompVis/stable-diffusion).\n",
    "\n",
    "Notebook by [deforum](https://discord.gg/upmXXsrwZc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBamKxcmNI7-"
   },
   "source": [
    "By using this Notebook, you agree to the following Terms of Use, and license:\n",
    "\n",
    "**Stablity.AI Model Terms of Use**\n",
    "\n",
    "This model is open access and available to all, with a CreativeML OpenRAIL-M license further specifying rights and usage.\n",
    "\n",
    "The CreativeML OpenRAIL License specifies:\n",
    "\n",
    "You can't use the model to deliberately produce nor share illegal or harmful outputs or content\n",
    "CompVis claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license\n",
    "You may re-distribute the weights and use the model commercially and/or as a service. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully)\n",
    "\n",
    "\n",
    "Please read the full license here: https://huggingface.co/spaces/CompVis/stable-diffusion-license"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4knibRpAQ06"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "form",
    "id": "2g-f7cQmf2Nt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA RTX A4000, 16376 MiB, 12620 MiB\n",
      "\n",
      "Local Path Variables:\n",
      "\n",
      "models_path: /content/models\n",
      "output_path: /content/output\n",
      "Setting up environment...\n",
      "Cloning into 'stable-diffusion'...\n",
      "remote: Enumerating objects: 1369, done.\u001b[K\n",
      "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
      "remote: Total 1369 (delta 12), reused 21 (delta 12), pack-reused 1344\u001b[K\n",
      "Receiving objects: 100% (1369/1369), 70.16 MiB | 41.50 MiB/s, done.\n",
      "Resolving deltas: 100% (737/737), done.\n",
      "Cloning into 'AdaBins'...\n",
      "remote: Enumerating objects: 80, done.\u001b[K\n",
      "remote: Total 80 (delta 0), reused 0 (delta 0), pack-reused 80\u001b[K\n",
      "Receiving objects: 100% (80/80), 558.94 KiB | 3.02 MiB/s, done.\n",
      "Resolving deltas: 100% (31/31), done.\n",
      "Cloning into 'MiDaS'...\n",
      "remote: Enumerating objects: 501, done.\u001b[K\n",
      "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
      "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
      "remote: Total 501 (delta 69), reused 46 (delta 44), pack-reused 409\u001b[K\n",
      "Receiving objects: 100% (501/501), 414.88 KiB | 3.35 MiB/s, done.\n",
      "Resolving deltas: 100% (167/167), done.\n",
      "Cloning into 'pytorch3d-lite'...\n",
      "remote: Enumerating objects: 55, done.\u001b[K\n",
      "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
      "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
      "remote: Total 55 (delta 30), reused 38 (delta 15), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (55/55), 29.59 KiB | 7.40 MiB/s, done.\n",
      "Resolving deltas: 100% (30/30), done.\n",
      "Cloning into 'k-diffusion'...\n",
      "remote: Enumerating objects: 427, done.\u001b[K\n",
      "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
      "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
      "remote: Total 427 (delta 130), reused 124 (delta 124), pack-reused 281\u001b[K\n",
      "Receiving objects: 100% (427/427), 76.34 KiB | 1.32 MiB/s, done.\n",
      "Resolving deltas: 100% (286/286), done.\n",
      "\n",
      "Environment set up in 36 seconds\n"
     ]
    }
   ],
   "source": [
    "SETUP = True\n",
    "\n",
    "if SETUP:\n",
    "    !python setup.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/content/models’: File exists\n",
      "mkdir: cannot create directory ‘/content/output’: File exists\n"
     ]
    }
   ],
   "source": [
    "# !pip install gdown\n",
    "# !gdown https://drive.google.com/uc?id=1N06uaEC-5c1ciC_CVwqfhD-IPbOtCVOa\n",
    "#!mkdir ../models\n",
    "# !mv sd-v1-4-full-ema.ckpt ../models/model.ckpt\n",
    "#@markdown **Model and Output Paths**\n",
    "# ask for the link\n",
    "# !mkdir /content/models\n",
    "# !mkdir /content/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ov3r4RD1tzsT"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0j7rgxvLvfay"
   },
   "source": [
    "### Animation Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63UOJvU3xdPS"
   },
   "source": [
    "### Prompts\n",
    "`animation_mode: None` batches on list of *prompts*. `animation_mode: 2D` uses *animation_prompts* key frame sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "2ujwkGZTcGev"
   },
   "outputs": [],
   "source": [
    "\n",
    "prompts = [\n",
    "    \"a beautiful forest by Asher Brown Durand, trending on Artstation\", # the first prompt I want\n",
    "    \"a beautiful portrait of a woman by Artgerm, trending on Artstation\", # the second prompt I want\n",
    "    #\"this prompt I don't want it I commented it out\",\n",
    "    #\"a nousr robot, trending on Artstation\", # use \"nousr robot\" with the robot diffusion model (see model_checkpoint setting)\n",
    "    #\"touhou 1girl komeiji_koishi portrait, green hair\", # waifu diffusion prompts can use danbooru tag groups (see model_checkpoint)\n",
    "    #\"this prompt has weights if prompt weighting enabled:2 can also do negative:-2\", # (see prompt_weighting)\n",
    "]\n",
    "\n",
    "animation_prompts = {\n",
    "    0: \"a beautiful apple, trending on Artstation\",\n",
    "    20: \"a beautiful banana, trending on Artstation\",\n",
    "    30: \"a beautiful coconut, trending on Artstation\",\n",
    "    40: \"a beautiful durian, trending on Artstation\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "# clean up unused memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deforum import render_input_video, render_animation, render_interpolation, render_image_batch, DeforumArgs, DeforumAnimArgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8RAo2zI-vQm"
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "cellView": "form",
    "id": "qH74gBWDd2oq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading custom settings from ../configs/current.txt\n",
      "{'W': 512, 'H': 512, 'seed': 9395209, 'sampler': 'klms', 'steps': 50, 'scale': 7, 'ddim_eta': 0, 'dynamic_threshold': None, 'static_threshold': None, 'save_samples': True, 'save_settings': True, 'display_samples': True, 'save_sample_per_step': False, 'show_sample_per_step': False, 'prompt_weighting': False, 'normalize_prompt_weights': True, 'log_weighted_subprompts': False, 'n_batch': 1, 'batch_name': 'StableFun', 'filename_format': '{timestring}_{index}_{prompt}.png', 'seed_behavior': 'iter', 'make_grid': False, 'grid_rows': 2, 'outdir': '/content/drive/MyDrive/AI/StableDiffusion/2022-10/StableFun', 'use_init': False, 'strength': 0.0, 'strength_0_no_init': True, 'init_image': None, 'use_mask': False, 'use_alpha_as_mask': False, 'mask_file': 'https://www.filterforge.com/wiki/images/archive/b/b7/20080927223728%21Polygonal_gradient_thumb.jpg', 'invert_mask': False, 'mask_brightness_adjust': 1.0, 'mask_contrast_adjust': 1.0, 'overlay_mask': True, 'mask_overlay_blur': 5, 'n_samples': 1, 'precision': 'autocast', 'C': 4, 'f': 8, 'prompt': '', 'timestring': '20221002091303', 'init_latent': None, 'init_sample': None, 'init_c': None}\n",
      "{'animation_mode': '2D', 'max_frames': 1000, 'border': 'replicate', 'angle': '0:(0)', 'zoom': '0:(1.04)', 'translation_x': '0:(10*sin(2*3.14*t/10))', 'translation_y': '0:(0)', 'translation_z': '0:(10)', 'rotation_3d_x': '0:(0)', 'rotation_3d_y': '0:(0)', 'rotation_3d_z': '0:(0)', 'flip_2d_perspective': False, 'perspective_flip_theta': '0:(0)', 'perspective_flip_phi': '0:(t%15)', 'perspective_flip_gamma': '0:(0)', 'perspective_flip_fv': '0:(53)', 'noise_schedule': '0: (0.02)', 'strength_schedule': '0: (0.65)', 'contrast_schedule': '0: (1.0)', 'color_coherence': 'Match Frame 0 LAB', 'diffusion_cadence': '1', 'use_depth_warping': True, 'midas_weight': 0.3, 'near_plane': 200, 'far_plane': 10000, 'fov': 40, 'padding_mode': 'border', 'sampling_mode': 'bicubic', 'save_depth_maps': False, 'video_init_path': '/content/video_in.mp4', 'extract_nth_frame': 1, 'overwrite_extracted_frames': True, 'use_mask_video': False, 'video_mask_path': '/content/video_in.mp4', 'interpolate_key_frames': False, 'interpolate_x_frames': 4, 'resume_from_timestring': False, 'resume_timestring': '20220829210106'}\n",
      "animaattttt {'0': 'a beautiful apple, trending on Artstation', '20': 'a beautiful banana, trending on Artstation', '30': 'a beautiful coconut, trending on Artstation', '40': 'a beautiful durian, trending on Artstation'} namespace(C=4, H=512, W=512, batch_name='StableFun', ddim_eta=0, display_samples=True, dynamic_threshold=None, f=8, filename_format='{timestring}_{index}_{prompt}.png', grid_rows=2, init_c=None, init_image=None, init_latent=None, init_sample=None, invert_mask=False, log_weighted_subprompts=False, make_grid=False, mask_brightness_adjust=1.0, mask_contrast_adjust=1.0, mask_file='https://www.filterforge.com/wiki/images/archive/b/b7/20080927223728%21Polygonal_gradient_thumb.jpg', mask_overlay_blur=5, n_batch=1, n_samples=1, normalize_prompt_weights=True, outdir='/content/drive/MyDrive/AI/StableDiffusion/2022-10/StableFun', overlay_mask=True, precision='autocast', prompt='', prompt_weighting=False, prompts={'0': 'a beautiful apple, trending on Artstation', '20': 'a beautiful banana, trending on Artstation', '30': 'a beautiful coconut, trending on Artstation', '40': 'a beautiful durian, trending on Artstation'}, sampler='klms', save_sample_per_step=False, save_samples=True, save_settings=True, scale=7, seed=9395209, seed_behavior='iter', show_sample_per_step=False, static_threshold=None, steps=50, strength=0.0, strength_0_no_init=True, timestring='20221002105330', use_alpha_as_mask=False, use_init=False, use_mask=False)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "render_animation() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [57], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# dispatch to appropriate renderer\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m anim_args\u001b[38;5;241m.\u001b[39manimation_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m anim_args\u001b[38;5;241m.\u001b[39manimation_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3D\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mrender_animation\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manim_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manimation_prompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m anim_args\u001b[38;5;241m.\u001b[39manimation_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo Input\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     64\u001b[0m     render_input_video(args, anim_args, animation_prompts)\n",
      "\u001b[0;31mTypeError\u001b[0m: render_animation() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from types import SimpleNamespace\n",
    "import time, random, json\n",
    "#@markdown **Load Settings**\n",
    "override_settings_with_file = True #@param {type:\"boolean\"}\n",
    "custom_settings_file = \"../configs/current.txt\"#@param {type:\"string\"}\n",
    "\n",
    "args_dict = DeforumArgs()\n",
    "anim_args_dict = DeforumAnimArgs()\n",
    "\n",
    "if override_settings_with_file:\n",
    "    print(f\"reading custom settings from {custom_settings_file}\")\n",
    "    if not os.path.isfile(custom_settings_file):\n",
    "        print('The custom settings file does not exist. The in-notebook settings will be used instead')\n",
    "    else:\n",
    "        with open(custom_settings_file, \"r\") as f:\n",
    "            jdata = json.loads(f.read())\n",
    "            animation_prompts = jdata[\"prompts\"]\n",
    "            args.prompts = animation_prompts\n",
    "            for i, k in enumerate(args_dict):\n",
    "                if k in jdata:\n",
    "                    args_dict[k] = jdata[k]\n",
    "                else:\n",
    "                    print(f\"key {k} doesn't exist in the custom settings data! using the default value of {args_dict[k]}\")\n",
    "            for i, k in enumerate(anim_args_dict):\n",
    "                if k in jdata:\n",
    "                    anim_args_dict[k] = jdata[k]\n",
    "                else:\n",
    "                    print(f\"key {k} doesn't exist in the custom settings data! using the default value of {anim_args_dict[k]}\")\n",
    "            print(args_dict)\n",
    "            print(anim_args_dict)\n",
    "\n",
    "            \n",
    "print(\"animaattttt\", animation_prompts, args)\n",
    "args = SimpleNamespace(**args_dict)\n",
    "anim_args = SimpleNamespace(**anim_args_dict)\n",
    "\n",
    "args.timestring = time.strftime('%Y%m%d%H%M%S')\n",
    "args.strength = max(0.0, min(1.0, args.strength))\n",
    "\n",
    "if args.seed == -1:\n",
    "    args.seed = random.randint(0, 2**32 - 1)\n",
    "if not args.use_init:\n",
    "    args.init_image = None\n",
    "if args.sampler == 'plms' and (args.use_init or anim_args.animation_mode != 'None'):\n",
    "    print(f\"Init images aren't supported with PLMS yet, switching to KLMS\")\n",
    "    args.sampler = 'klms'\n",
    "if args.sampler != 'ddim':\n",
    "    args.ddim_eta = 0\n",
    "\n",
    "if anim_args.animation_mode == 'None':\n",
    "    anim_args.max_frames = 1\n",
    "elif anim_args.animation_mode == 'Video Input':\n",
    "    args.use_init = True\n",
    "\n",
    "# clean up unused memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# dispatch to appropriate renderer\n",
    "if anim_args.animation_mode == '2D' or anim_args.animation_mode == '3D':\n",
    "    render_animation(args, anim_args, animation_prompts)\n",
    "elif anim_args.animation_mode == 'Video Input':\n",
    "    render_input_video(args, anim_args, animation_prompts)\n",
    "elif anim_args.animation_mode == 'Interpolation':\n",
    "    render_interpolation(args, anim_args, animation_prompts)\n",
    "else:\n",
    "    render_image_batch(args)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zV0J_YbMCTx"
   },
   "source": [
    "# Create video from frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "no2jP8HTMBM0"
   },
   "outputs": [],
   "source": [
    "skip_video_for_run_all = True #@param {type: 'boolean'}\n",
    "fps = 12 #@param {type:\"number\"}\n",
    "#@markdown **Manual Settings**\n",
    "use_manual_settings = False #@param {type:\"boolean\"}\n",
    "image_path = \"/content/drive/MyDrive/AI/StableDiffusion/2022-09/20220903000939_%05d.png\" #@param {type:\"string\"}\n",
    "mp4_path = \"/content/drive/MyDrive/AI/StableDiffu'/content/drive/MyDrive/AI/StableDiffusion/2022-09/sion/2022-09/20220903000939.mp4\" #@param {type:\"string\"}\n",
    "render_steps = True  #@param {type: 'boolean'}\n",
    "path_name_modifier = \"x0_pred\" #@param [\"x0_pred\",\"x\"]\n",
    "\n",
    "\n",
    "if skip_video_for_run_all == True:\n",
    "    print('Skipping video creation, uncheck skip_video_for_run_all if you want to run it')\n",
    "else:\n",
    "    import os\n",
    "    import subprocess\n",
    "    from base64 import b64encode\n",
    "\n",
    "    print(f\"{image_path} -> {mp4_path}\")\n",
    "\n",
    "    if use_manual_settings:\n",
    "        max_frames = \"200\" #@param {type:\"string\"}\n",
    "    else:\n",
    "        if render_steps: # render steps from a single image\n",
    "            fname = f\"{path_name_modifier}_%05d.png\"\n",
    "            all_step_dirs = [os.path.join(args.outdir, d) for d in os.listdir(args.outdir) if os.path.isdir(os.path.join(args.outdir,d))]\n",
    "            newest_dir = max(all_step_dirs, key=os.path.getmtime)\n",
    "            image_path = os.path.join(newest_dir, fname)\n",
    "            print(f\"Reading images from {image_path}\")\n",
    "            mp4_path = os.path.join(newest_dir, f\"{args.timestring}_{path_name_modifier}.mp4\")\n",
    "            max_frames = str(args.steps)\n",
    "        else: # render images for a video\n",
    "            image_path = os.path.join(args.outdir, f\"{args.timestring}_%05d.png\")\n",
    "            mp4_path = os.path.join(args.outdir, f\"{args.timestring}.mp4\")\n",
    "            max_frames = str(anim_args.max_frames)\n",
    "\n",
    "    # make video\n",
    "    cmd = [\n",
    "        'ffmpeg',\n",
    "        '-y',\n",
    "        '-vcodec', 'png',\n",
    "        '-r', str(fps),\n",
    "        '-start_number', str(0),\n",
    "        '-i', image_path,\n",
    "        '-frames:v', max_frames,\n",
    "        '-c:v', 'libx264',\n",
    "        '-vf',\n",
    "        f'fps={fps}',\n",
    "        '-pix_fmt', 'yuv420p',\n",
    "        '-crf', '17',\n",
    "        '-preset', 'veryfast',\n",
    "        '-pattern_type', 'sequence',\n",
    "        mp4_path\n",
    "    ]\n",
    "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    if process.returncode != 0:\n",
    "        print(stderr)\n",
    "        raise RuntimeError(stderr)\n",
    "\n",
    "    mp4 = open(mp4_path,'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    display.display( display.HTML(f'<video controls loop><source src=\"{data_url}\" type=\"video/mp4\"></video>') )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
